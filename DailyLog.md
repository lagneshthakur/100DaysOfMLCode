# 100 Days Of ML Code - LOG

## Day 1 : July 12 , 2018
 
**Today's Progress** : From Google's crash course -
* Introduction to ML
* ML Terminology
* Descending into ML
* Reducing Loss - Gradient Descent

Got this cool cheat sheet, [Markdown Cheatsheet](https://github.com/tchapi/markdown-cheatsheet/blob/master/README.md)

**Thoughts** : Didn't know where to start, went through all the links, got terrified. Decided to start with Google's crash course - https://developers.google.com/machine-learning/crash-course/ml-intro
Eagerly waiting for tomorrow to continue with the lectures

## Day 2 : July 13 , 2018
 
**Today's Progress** : From Google's crash course -
* Reducing Loss - Learning Rate
* Reducing Loss - Stochastic Gradient Descent
* First Steps with TF - 
	* Intro to Pandas

**Thoughts** : Continued with the lectures, taking it on my own pace to start with. Played in the [Playground](http://playground.tensorflow.org). Will continue with Linear Regression using TensorFlow tomorrow

## Day 3 : July 14 , 2018
 
**Today's Progress** : From Udemy's Python for Data Science course -
* NLP using TF-IDF
* Spam/Ham classification of messages

**Thoughts** : Shifted gears a bit as I heard about TF-IDF from a friend. Just wanted to get some output using the code.

**Link of Work** : [Commit](https://github.com/lagneshthakur/100DaysOfMLCode/commit/dea1dacb39a38448297c0f697f743487b5b9a2a9)

## Day 4 : July 15 , 2018
 
**Today's Progress** : From Google's crash course -
* First steps with TF

**Thoughts** : Back to Google's tutorials, didn't get all of it. Need to get better at understanding things.

**Link of Work** : [Commit](https://github.com/lagneshthakur/100DaysOfMLCode/commit/5216777f1400f519891b33eabd49c47c863b91e5)

## Day 5 : July 17 , 2018

**Today's Progress** : From Google's crash course -
* First steps with TF

**Thoughts** : Re-did the same tutorial and tweaked with the code to get better understanding of intermediate logic
